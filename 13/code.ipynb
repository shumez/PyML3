{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Parallelizing Neural Netowrk Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 13.01. TensorFlow and training performance\n",
    "  - 13.01.01. Performance challenges\n",
    "  - 13.01.02. What is TensorFlow?\n",
    "  - 13.01.03. How we will learn TensorFlow\n",
    "- 13.02. First steps with TensorFlow\n",
    "  - 13.02.01. Installing TensorFlow\n",
    "  - 13.02.02. Creating tensors in TensorFlow\n",
    "  - 13.02.03. Manipulating the data type and shape of a tensor\n",
    "  - 13.02.04. Applying mathematical operations to tensors\n",
    "  - 13.02.05. Split, stack, and concatenate tensors\n",
    "  - 13.02.06. Building input pipelines using tf.data – the TensorFlow Dataset API\n",
    "    - 13.02.06.01. Creating a TensorFlow Dataset from existing tensors\n",
    "    - 13.02.06.02. Combining two tensors into a joint dataset\n",
    "    - 13.02.06.03. Shuffle, batch, and repeat\n",
    "    - 13.02.06.04. Creating a dataset from files on your local storage disk\n",
    "    - 13.02.06.05. Fetching available datasets from the `tensorflow_datasets` library\n",
    "- 13.03. Building an NN model in TensorFlow\n",
    "  - 13.03.01. The TensorFlow Keras API (tf.keras)\n",
    "  - 13.03.02. Building a linear regression model\n",
    "  - 13.03.03. Model training via the `.compile()` and `.fit()` methods \n",
    "  - 13.03.04. Building a multilayer perceptron for classifying flowers in the Iris dataset\n",
    "  - 13.03.05. Evaluating the trained model on the test dataset\n",
    "  - 13.03.06. Saving and reloading the trained model\n",
    "- 13.04. Choosing activation functions for multilayer NNs\n",
    "  - 13.04.01. Logistic function recap\n",
    "  - 13.04.02. Estimating class probabilities in multiclass classification via the softmax function\n",
    "  - 13.04.03. Broadening the output spectrum using a hyperbolic tangent\n",
    "  - 13.04.04. Rectified linear unit activation\n",
    "- 13.05. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-12 10:48:06\n",
      "----------------------\n",
      "python\t\t3.6.7\n",
      "----------------------\n",
      "numpy\t\t1.18.5\n",
      "scipy\t\t1.4.1\n",
      "pandas\t\t0.25.1\n",
      "matplotlib\t3.1.1\n",
      "imageio\t\t2.5.0\n",
      "----------------------\n",
      "ipython\t\t7.8.0\n",
      "----------------------\n",
      "sklearn\t\t0.20.4\n",
      "tensorflow\t2.3.0\n",
      "nltk\t\t3.2.4\n",
      "----------------------\n",
      "networkx\t2.0\n"
     ]
    }
   ],
   "source": [
    "%run -i 'watermark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.01. TensorFlow and training performance\n",
    "\n",
    "### 13.01.01. Performance challenges\n",
    "\n",
    "### 13.01.02. What is TensorFlow?\n",
    "\n",
    "![Fig.13.1](https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch13/images/01.png)\n",
    "\n",
    "### 13.01.03. How we will learn TensorFlow\n",
    "\n",
    "## 13.02. First steps with TensorFlow\n",
    "\n",
    "### 13.02.01. Installing TensorFlow\n",
    "\n",
    "### 13.02.02. Creating ttensors in TensorFlow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = tf.ones((2, 3))\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.02.03. Manipulating the data type and shape of a tensor\n",
    "\n",
    "- `tf.cast()`: change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rank: dim\n",
    "- shape\n",
    "\n",
    "useful fn\n",
    "\n",
    "- `tf.transpose()`: change shape\n",
    "- `tf.reshape()`: add new dim\n",
    "- `tf.squeeze()`: squeeze an unnecessary dim\n",
    "\n",
    "###### transposing a tensor\n",
    "\n",
    "`tf.transpose(tensor)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) --> (5, 3)\n"
     ]
    }
   ],
   "source": [
    "t = tf.random.uniform(shape=(3, 5))\n",
    "t_tr = tf.transpose(t)\n",
    "print(t.shape, '-->', t_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### reshaping a tensor\n",
    "\n",
    "`tf.reshape(tensor, shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,) --> (5, 6)\n"
     ]
    }
   ],
   "source": [
    "t = tf.zeros((30,))\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(t.shape, '-->', t_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### removing the unnecessary dims\n",
    "\n",
    "`tf.squeeze(tensor, axis)`\n",
    "\n",
    "squeeze listed axis (#0, #1, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 1, 4, 1) --> (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "t_sqz = tf.squeeze(t, axis=(2,4))\n",
    "print(t.shape, '-->', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.02.04. Applying mathematical operations to tensors \n",
    "\n",
    "- element-wise product\n",
    "- matrix multiplication\n",
    "- norm\n",
    "\n",
    "standard norm dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t1 = tf.random.uniform(shape=(5,2), minval=-1.0, maxval=1.0)\n",
    "t2 = tf.random.normal(shape=(5,2), mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.multiply(tensor1, tensor2)`:  element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]]\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.math.reduce_mean()`: mean\n",
    "\n",
    "`tf.math.reduce_sum()`: sum\n",
    "\n",
    "`tf.math.reduce_std()`: standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ t_1 \\times t_2^T $ \n",
    "\n",
    "$ t_{5 \\times 2} \\times t_{2 \\times 5} = t_{5 \\times 5} $\n",
    "\n",
    "`tf.linalg.matmul(tensor_a, tensor_b, transpose_a=False, transpose_b=False)`: matrix-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]]\n"
     ]
    }
   ],
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ t_1^T \\times t_2 $\n",
    "\n",
    "$ t_{2 \\times 5} \\times t_{5 \\times 2} = t_{2 \\times 2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.711  0.302]\n",
      " [ 0.371 -1.049]]\n"
     ]
    }
   ],
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.norm(tensor, ord='', axis=None)`\n",
    "\n",
    "ord: \n",
    "`'fro'`, `'euclidean'`, `1`, `2`, `np.inf`\n",
    "\n",
    "$L^p$ e.g., $L^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "source": [
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.02.05. Split, stack, and concatenate tensors\n",
    "\n",
    "spliting, stacking \n",
    "\n",
    "`tf.split(tensor, num_or_size_splits=number)`\n",
    "\n",
    "providing the num of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16513085 0.9014813  0.6309742  0.4345461  0.29193902 0.64250207]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.16513085, 0.9014813 ], dtype=float32),\n",
       " array([0.6309742, 0.4345461], dtype=float32),\n",
       " array([0.29193902, 0.64250207], dtype=float32)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=3)\n",
    "[item.numpy() for item in t_spllits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "providing the sizes of different splits\n",
    "\n",
    "`tf.split(tensor, num_or_size_splits=[number, number])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16513085 0.9014813  0.6309742  0.4345461  0.29193902]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.16513085, 0.9014813 , 0.6309742 ], dtype=float32),\n",
       " array([0.4345461 , 0.29193902], dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.concat([tensor, tensor], axis=number)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((2,))\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((3,))\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow docs](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.02.06. Builing input pipleines using tf.data - the TensorFlow Dateaset API\n",
    "\n",
    "`.fit()`\n",
    "\n",
    "#### 13.02.06.01. Creating a TensorFlow Dataset from existing tensors\n",
    "\n",
    "`tf.data.Dataset.from_tensor_slices()`\n",
    "return `Dataset` (can iterate through the individual elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create batches from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: [1.2 3.4 7.5]\n",
      "batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(3)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('batch {}:'.format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.batch()` method has optional arg `drop_remainder`\n",
    "`drop_remainder` useful for cases whten # of elements in teh tensor is NOT divisble by desired batch size\n",
    "\n",
    "`shuffle`, `batch`, `repeat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.02.06.02. Combining two tensors into a joint dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4,3], dtype=tf.float32)\n",
    "t_y = tf.range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: [0.16513085 0.9014813  0.6309742 ]   y: 0\n",
      "  x: [0.4345461  0.29193902 0.64250207]   y: 1\n",
      "  x: [0.9757855  0.43509948 0.6601019 ]   y: 2\n",
      "  x: [0.60489583 0.6366315  0.6144488 ]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('  x:', example[0].numpy(), \n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zip()` fn joint dataset \n",
    "\n",
    "alternatively  \n",
    "`tf.data.Dataset.from_tensor_slices()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: [0.16513085 0.9014813  0.6309742 ]   y: 0\n",
      "  x: [0.4345461  0.29193902 0.64250207]   y: 1\n",
      "  x: [0.9757855  0.43509948 0.6601019 ]   y: 2\n",
      "  x: [0.60489583 0.6366315  0.6144488 ]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('  x:', example[0].numpy(), \n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: [-0.6697383   0.80296254  0.26194835]   y: 0\n",
      "  x: [-0.13090777 -0.41612196  0.28500414]   y: 1\n",
      "  x: [ 0.951571   -0.12980103  0.32020378]   y: 2\n",
      "  x: [0.20979166 0.27326298 0.22889757]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "for example in ds_trans:\n",
    "    print('  x:', example[0].numpy(), \n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.map()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.02.06.03. Shuffle, batch, and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: [0.9757855  0.43509948 0.6601019 ]   y: 2\n",
      "  x: [0.4345461  0.29193902 0.64250207]   y: 1\n",
      "  x: [0.16513085 0.9014813  0.6309742 ]   y: 0\n",
      "  x: [0.60489583 0.6366315  0.6144488 ]   y: 3\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\n",
    "\n",
    "for example in ds:\n",
    "    print('  x:', example[0].numpy(), \n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.shuffle` \n",
    "arg `buffer_size` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-x:\n",
      " [[0.16513085 0.9014813  0.6309742 ]\n",
      " [0.4345461  0.29193902 0.64250207]\n",
      " [0.9757855  0.43509948 0.6601019 ]]\n",
      "Batch-y:\n",
      " [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(batch_size=3, \n",
    "                    drop_remainder=False)\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "print('Batch-x:\\n', batch_x.numpy())\n",
    "print('Batch-y:\\n', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (1, 3) [3]\n",
      "2 (3, 3) [0 1 2]\n",
      "3 (1, 3) [3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (3, 3) [3 0 1]\n",
      "2 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [2 1]\n",
      "1 (2, 3) [0 3]\n",
      "2 (2, 3) [0 3]\n",
      "3 (2, 3) [1 2]\n",
      "4 (2, 3) [3 0]\n",
      "5 (2, 3) [1 2]\n"
     ]
    }
   ],
   "source": [
    "## Order 1: shuffle -> batch -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [2 3]\n",
      "2 (2, 3) [0 1]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [2 3]\n",
      "5 (2, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "## Order 2: batch -> shuffle -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 13.01. TensorFlow and training performance\n",
    "  - 13.01.01. Performance challenges\n",
    "  - 13.01.02. What is TensorFlow?\n",
    "  - 13.01.03. How we will learn TensorFlow\n",
    "- 13.02. First steps with TensorFlow\n",
    "  - 13.02.01. Installing TensorFlow\n",
    "  - 13.02.02. Creating tensors in TensorFlow\n",
    "  - 13.02.03. Manipulating the data type and shape of a tensor\n",
    "  - 13.02.04. Applying mathematical operations to tensors\n",
    "  - 13.02.05. Split, stack, and concatenate tensors\n",
    "  - 13.02.06. Building input pipelines using tf.data – the TensorFlow Dataset API\n",
    "    - 13.02.06.01. Creating a TensorFlow Dataset from existing tensors\n",
    "    - 13.02.06.02. Combining two tensors into a joint dataset\n",
    "    - 13.02.06.03. Shuffle, batch, and repeat\n",
    "    - 13.02.06.04. Creating a dataset from files on your local storage disk\n",
    "    - 13.02.06.05. Fetching available datasets from the `tensorflow_datasets` library\n",
    "- 13.03. Building an NN model in TensorFlow\n",
    "  - 13.03.01. The TensorFlow Keras API (tf.keras)\n",
    "  - 13.03.02. Building a linear regression model\n",
    "  - 13.03.03. Model training via the `.compile()` and `.fit()` methods \n",
    "  - 13.03.04. Building a multilayer perceptron for classifying flowers in the Iris dataset\n",
    "  - 13.03.05. Evaluating the trained model on the test dataset\n",
    "  - 13.03.06. Saving and reloading the trained model\n",
    "- 13.04. Choosing activation functions for multilayer NNs\n",
    "  - 13.04.01. Logistic function recap\n",
    "  - 13.04.02. Estimating class probabilities in multiclass classification via the softmax function\n",
    "  - 13.04.03. Broadening the output spectrum using a hyperbolic tangent\n",
    "  - 13.04.04. Rectified linear unit activation\n",
    "- 13.05. Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
