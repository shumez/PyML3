{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Classifying Images with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [15.01. The building blocks of CNNs][1501]\n",
    "    - [15.01.01. Understanding CNNs and features hierachies][150101]\n",
    "    - [15.01.02. Performing discrete convolutions][150102]\n",
    "        - [15.01.02.01. Discrete convolutions in one dimension][15010201]\n",
    "        - [15.01.02.02. Padding inputs to control the size of the output feature maps][15010202]\n",
    "        - [15.01.02.03. Determining the size of the convolution output][15010203]\n",
    "        - [15.01.02.04. Performing a discrete convoution in 2D][15010204]\n",
    "    - [15.01.03. Subsampling layers][150103]\n",
    "- [15.02. Putting everything together - implementing a CNN][1502]\n",
    "    - [15.02.01. Working with multiple input or color channels][150201]\n",
    "    - [15.02.02. Regularizing an NN with dropout][150202]\n",
    "    - [15.02.03. Loss functions for classification][150203]\n",
    "- [15.03. Implementing a deep CNN using TensorFlow][1503]\n",
    "    - [15.03.01. The multilayer CNN architecture][150301]\n",
    "    - [15.03.02. Loading and preprocessing the data][150302]\n",
    "    - [15.03.03. Implemeting a CNN using the TensorFlow Keras API][150303]\n",
    "        - [15.03.03.01. Configuration CNN layers in Keras][15030301]\n",
    "        - [15.03.03.02. Constructing a CNN in Keras][15030302]\n",
    "- [15.04. Gender classigcation from face images using][1504]\n",
    "    - [15.04.01. Loading the CelebA dataset][150401]\n",
    "    - [15.04.02. Image transformation and data augmentation][150401]\n",
    "    - [15.04.03. Training a CNN gender classifier][150403]\n",
    "- [15.05. Summary][1505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: scipy pandas matplotlib sklearn tensorflow nltk\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-05-02 17:49:05\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.10\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "numpy              : 1.19.2\n",
      "scipy              : 1.6.2\n",
      "pandas             : 1.2.2\n",
      "matplotlib         : 3.3.2\n",
      "sklearn            : 0.24.1\n",
      "tensorflow         : 2.0.0\n",
      "tensorflow_datasets: not installed\n",
      "nltk               : 3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -u -d -t -v -p numpy,scipy,pandas,matplotlib,sklearn,tensorflow,tensorflow_datasets,nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.01. The building blocks of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.01.01. Understanding CNNs and features hierachies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**salient (relevant) features**\n",
    "\n",
    "**feature hierarchy**\n",
    "\n",
    "**feature map**\n",
    "\n",
    "**local receptive field**\n",
    "\n",
    "2 ideas:\n",
    "\n",
    "- **sparse connectivity**\n",
    "- **parameter-sharing**\n",
    "\n",
    "$w_{ij}$  \n",
    "input unit $i$, output unit $j$\n",
    "\n",
    "pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.01.02. Performing discrete convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(discrete) convolution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.01.02.01. Dscrete convolutions in one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vec $x$, $w$  \n",
    "$y = x \\ast w$\n",
    "\n",
    "signal $x$, filter/kernel $w$\n",
    "\n",
    "$$y = x \\ast w \\rightarrow y[i] = \\sum_{k=-\\infty}^{+\\infty}{x[i-k]w[k]}$$\n",
    "\n",
    "**(zero-)padding**\n",
    "\n",
    "$m ≤ n$ $x^p$\n",
    "\n",
    "$x$ have $n$ elements, $w$ have $m$ elements\n",
    "\n",
    "padded vector $x^p$\n",
    "\n",
    "$$y = x \\ast w \\rightarrow y[i] = \\sum_{k=0}^{k=m-1}{x^p[i+m-k] w[k]}$$\n",
    "\n",
    "$w^r$\n",
    "\n",
    "$x[i:i+m]$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.01.02.02. Padding inputs to control the size of the output feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.01.02.03. Determining the size of the convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convld(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    \n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([zero_pad, x_padded, zero_pad])\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for i in range(0, int(len(x)/s), s):\n",
    "        res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
    "        \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convid implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n"
     ]
    }
   ],
   "source": [
    "# Testing:\n",
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Convid implementation:', convld(x, w, p=2, s=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "source": [
    "print('Numpy Results:', np.convolve(x, w, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.01.02.04. Performing a discrete convoution in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(0,0), s=(1,1)):\n",
    "    W_rot = np.array(W)[::-1,::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0]+X_orig.shape[0], \n",
    "             p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
    "    res = []\n",
    "    \n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0])/s[0])+1, s[0]):\n",
    "        res.append([])\n",
    "        \n",
    "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1])/s[1])+1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0], j:j+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    \n",
    "    return(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Impplementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [[1,3,2,4], [5,6,1,3], [1,2,0,2], [3,4,3,2]]\n",
    "W = [[1,0,3], [1,2,1], [0,1,1]]\n",
    "\n",
    "Y = conv2d(X,W, p=(1,1), s=(1,1))\n",
    "\n",
    "print('Conv2d Impplementation:\\n', Y)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, sharey=True)\n",
    "ax[0].imshow(Y)\n",
    "ax[1].imshow(X)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[0].text(j, i, Y[i, j], ha='center', va='center', color='w')\n",
    "\n",
    "X = np.array(X)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[1].text(j, i, X[i, j], ha='center', va='center', color='w')\n",
    "        \n",
    "\n",
    "ax[0].set_yticks(np.arange(4))\n",
    "\n",
    "ax[0].set_title('Y')\n",
    "ax[1].set_title('X')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "print('SciPy Results:\\n', scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.01.03. Subsampling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.02. Putting everything together - implementing a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.01. Working with multiple input or color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reading an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unit8`: unsigned 8-bit integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (332, 332, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img_raw = tf.io.read_file('watchmen.png')\n",
    "img = tf.image.decode_image(img_raw)\n",
    "print('Image shape:', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (332, 332, 4)\n",
      "Number data type: uint8\n",
      "[[[255 236   0 255]\n",
      "  [255 236   0 255]]\n",
      "\n",
      " [[255 236   0 255]\n",
      "  [255 236   0 255]]]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img = imageio.imread('watchmen.png')\n",
    "print('Image shape:', img.shape)\n",
    "\n",
    "print('Number data type:', img.dtype)\n",
    "\n",
    "print(img[100:102, 100:102, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.02. Regularizing an NN with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "conv_layer = keras.layers.Conv2D(\n",
    "    filters=16, \n",
    "    kernel_size=(3,3), kernel_regularizer=keras.regularizers.l2(.001))\n",
    "\n",
    "fc_layer = keras.layers.Dense(\n",
    "    units=16, \n",
    "    kernel_regularizer=keras.regularizers.l2(.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.03. Loss functions for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE \n",
      "(w Probas): 0.3711 (w Logits): 0.3711\n",
      "\n",
      "CCE \n",
      "(w Probas): 0.5996 (w Logits): 0.5996\n",
      "\n",
      "Sparse CCE \n",
      "(w Probas): 0.5996 (w Logits): 0.5996\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "### Binary Crossentropy\n",
    "\n",
    "bce_probas = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "bce_logits = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "logits = tf.constant([0.8])\n",
    "probas = tf.keras.activations.sigmoid(logits)\n",
    "\n",
    "tf.print(\n",
    "    'BCE \\n(w Probas): {:.4f}'.format(\n",
    "        bce_probas(y_true=[1], y_pred=probas)), \n",
    "    '(w Logits): {:.4f}\\n'.format(\n",
    "        bce_logits(y_true=[1], y_pred=logits)))\n",
    "\n",
    "\n",
    "### Categorical Crossentropy\n",
    "\n",
    "cce_probas = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "cce_logits = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "logits = tf.constant([[1.5, 0.8, 2.1]])\n",
    "probas = tf.keras.activations.softmax(logits)\n",
    "\n",
    "tf.print(\n",
    "    'CCE \\n(w Probas): {:.4f}'.format(\n",
    "        cce_probas(y_true=[0, 0, 1], y_pred=probas)), \n",
    "    '(w Logits): {:.4f}\\n'.format(\n",
    "        cce_logits(y_true=[0, 0, 1], y_pred=logits)))\n",
    "\n",
    "### Sparcse Categorical Crossentropy\n",
    "\n",
    "sp_cce_probas = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "sp_cce_logits = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "tf.print(\n",
    "    'Sparse CCE \\n(w Probas): {:.4f}'.format(\n",
    "        sp_cce_probas(y_true=[2], y_pred=probas)), \n",
    "    '(w Logits): {:.4f}'.format(\n",
    "        sp_cce_logits(y_true=[2], y_pred=logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.03. Implementing a deep CNN using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.03.01. The multilayer CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.03.02. Loading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist (11.06 MiB) to /Users/shumez/tensorflow_datasets/mnist/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1da483b12d24062aa8f4380a8266a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c549e0097e324e78b442163933743345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Size...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdd631a7d8d4257a33b06e86a4a5c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Extraction completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "/Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "/Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "/Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910de1f4d6424d0ea9cdeaed3ce51a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658aafcc42f74202bec538532d3bae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Shuffling...'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shumez/opt/anaconda3/envs/pyml3env/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf310198f8b84f688a8614807e27bd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b974215980943d8b0c757ed5a4f4874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6107848361df4e0ea49a76010a56014f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ca36be15d04da997574968fc4b3eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87fedad56624391b29eb1760f523d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635485c428ce40c7bf4f70f375f15ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a92c605f0468b96c90a47f0303997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff4659fec56415c8dac9893837d5514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ddd401933e4695a8a925359b40342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68170a97be914924a0425bc3bc0d823f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343de56be58f4b618eded7778683397f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bf24c8c6cb4838b1ae85759dde373f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f491f503874e6d87d71ae2412c2a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625e74d61cba44589dad8825cf2640a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89c8ee4b2784564ac26accd1552a7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e674a0fb6f476b89c170e0ec733ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7a0c4c4ce94017ad34782eaa911843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50d0f30c9844ec4ac8afac1a97276d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b6f1f1d77d4bd9b15368a800bd1f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99855b0a83d4478abfc1ab75b0e75004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=6000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45accac285814c1dba66a1b69aa0821c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671f76731f2e47b1ba54f91520f7331b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Shuffling...'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c0c890d2144e659c13fbcfbcf51eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Reading...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f99f78fd6447f5b85a4579d77ba358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Writing...'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/shumez/tensorflow_datasets/mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "## Loading the data\n",
    "mnist_bldr = tfds.builder('mnist')\n",
    "mnist_bldr.download_and_prepare()\n",
    "datasets = mnist_bldr.as_dataset(shuffle_files=False)\n",
    "mnist_train_orig = datasets['train']\n",
    "mnist_test_orig = datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "mnist_train = mnist_train_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32)/255.0, \n",
    "                 tf.cast(item['label'], tf.int32)))\n",
    "mnist_test = mnist_test_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32)/255.0, \n",
    "                  tf.cast(item['label'], tf.int32)))\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "mnist_train = mnist_train.shuffle(buffer_size=BUFFER_SIZE, \n",
    "                                  reshuffle_each_iteration=False)\n",
    "mnist_valid = mnist_train.take(10000).batch(BATCH_SIZE)\n",
    "mnist_train = mnist_train.skip(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.03.03. Implemeting a CNN using the TensorFlow Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.03.03.01. Configuration CNN layers in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.03.03.02. Constructing a CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=32, \n",
    "    kernel_size=(5,5), \n",
    "    strides=(1,1), \n",
    "    padding='same', \n",
    "    data_format='channels_last', \n",
    "    name='conv_1', \n",
    "    activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2,2), \n",
    "    name='pool_1'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=64, \n",
    "    kernel_size=(5,5), \n",
    "    strides=(1,1), \n",
    "    padding='same', \n",
    "    name='conv_2', \n",
    "    activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2,2), \n",
    "    name='pool_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 7, 7, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_output_shape(input_shape=(16,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1024, name='fc_1', activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(\n",
    "    rate=.5))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, name='fc_2', activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.04. Gender classigcation from face images using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.04.01. Loading the CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.04.02. Image transformation and data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.04.03. Training a CNN gender classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.05. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
