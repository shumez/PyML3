{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Classifying Images with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-12 15:12:18\n",
      "----------------------\n",
      "python\t\t3.6.7\n",
      "----------------------\n",
      "numpy\t\t1.16.2\n",
      "scipy\t\t1.1.0\n",
      "pandas\t\t0.25.1\n",
      "matplotlib\t3.1.1\n",
      "imageio\t\t2.5.0\n",
      "----------------------\n",
      "ipython\t\t7.8.0\n",
      "----------------------\n",
      "sklearn\t\t0.20.4\n",
      "tensorflow\t1.13.1\n",
      "nltk\t\t3.2.4\n"
     ]
    }
   ],
   "source": [
    "%run -i  'watermark.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.01. The building blocks of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.01.01. Understanding CNNs and features hierachies\n",
    "### 15.01.02. Performing discrete convolutions\n",
    "#### 15.01.02.01. Dscrete convolutions in one dimension\n",
    "#### 15.01.02.02. Padding inputs to control the size of the output feature maps\n",
    "#### 15.01.02.03. Determining the size of the convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convid(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    \n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([zero_pad, x_padded, zero_pad])\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for i in range(0, int(len(x)/s), s):\n",
    "        res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
    "        \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convid implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Convid implementation:', convid(x, w, p=2, s=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "source": [
    "print('Numpy Results:', np.convolve(x, w, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.01.02.04. Performing a discrete convoution in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(0,0), s=(1,1)):\n",
    "    W_rot = np.array(W)[::-1,::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0]+X_orig.shape[0], \n",
    "             p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
    "    res = []\n",
    "    \n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0])/s[0])+1, s[0]):\n",
    "        res.append([])\n",
    "        \n",
    "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1])/s[1])+1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0], j:j+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    \n",
    "    return(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Impplementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n"
     ]
    }
   ],
   "source": [
    "X = [[1,3,2,4], [5,6,1,3], [1,2,0,2], [3,4,3,2]]\n",
    "W = [[1,0,3], [1,2,1], [0,1,1]]\n",
    "\n",
    "print('Conv2d Impplementation:\\n', conv2d(X,W, p=(1,1), s=(1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "print('SciPy Results:\\n', scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.01.03. Subsampling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.02. Putting everything together - implementing a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.01. Working with multiple input or color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: <unknown>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img_raw = tf.io.read_file('~/Documents/Figure/graph.jpg')\n",
    "img = tf.image.decode_image(img_raw)\n",
    "print('Image shape:', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1563, 1563, 3)\n",
      "Number data type: uint8\n",
      "[[[1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]]]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img = imageio.imread('~/Documents/Figure/graph.jpg')\n",
    "print('Image shape:', img.shape)\n",
    "\n",
    "print('Number data type:', img.dtype)\n",
    "\n",
    "print(img[100:102, 100:102, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.02. Regularizing an NN with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "conv_layer = keras.layers.Conv2D(\n",
    "    filters=16, \n",
    "    kernel_size=(3,3), kernel_regularizer=keras.regularizers.l2(.001))\n",
    "\n",
    "fc_layer = keras.layers.Dense(\n",
    "    units=16, \n",
    "    kernel_regularizer=keras.regularizers.l2(.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.02.03. Loss functions for classification\n",
    "\n",
    "## 15.03. Implementing a deep CNN using TensorFlow\n",
    "\n",
    "### 15.03.01. The multilayer CNN architecture\n",
    "### 15.03.02. Loading and preprocessing the data\n",
    "### 15.03.03. Implemeting a CNN using the TensorFlow Keras API\n",
    "\n",
    "#### 15.03.03.01. Configuration CNN layers in Keras\n",
    "#### 15.03.03.02. Constructing a CNN in Keras\n",
    "\n",
    "## 15.04. Gender classigcation from face images using\n",
    "\n",
    "### 15.04.01. Loading the CelebA dataset\n",
    "### 15.04.02. Image transformation and data augmentation\n",
    "### 15.04.03. Training a CNN gender classifier\n",
    "\n",
    "## 15.05. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
